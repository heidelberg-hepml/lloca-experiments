# hyperparameters from https://arxiv.org/pdf/2201.08187 section 3.3
# alternatively https://github.com/sdogsq/LorentzNet-release/blob/main/top_tagging.py
# we use a simpler learning rate scheduler for convenience
batchsize: 128
lr: 1e-3
weight_decay: 0.01
iterations: 336000 # 35 epochs
validate_every_n_steps: 9600 # after each epoch
optimizer: AdamW
scheduler: CosineAnnealingLR

defaults:
 - tag_default
